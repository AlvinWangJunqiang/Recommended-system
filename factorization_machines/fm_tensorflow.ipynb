{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将列表转为稀疏矩阵\n",
    "Here we created a utility function to create a sparse matrix (that is needed by factorization machines) from a list of user/item ids.\n",
    "\n",
    "Check this gist for more details about this utitly function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# 数据转换\n",
    "def vectorize_dic(dic, ix=None, p=None, n=0, g=0):\n",
    "    '''\n",
    "    对列表中对每一列（每个内部列表是一组与特征对应的值）创建一个csr矩阵。\n",
    "\n",
    "    parameters:\n",
    "    -----------\n",
    "    dic -- 特征列表的字典, 即字典的key为特征名\n",
    "    ix -- 生成器索引(default None)\n",
    "    p -- 特征空间的维度(稀疏空间的特征数目) (default None)\n",
    "    '''\n",
    "    if ix == None:\n",
    "        ix = dict()\n",
    "\n",
    "    # 矩阵大小\n",
    "    nz = n * g\n",
    "\n",
    "    # 列索引\n",
    "    col_ix = np.empty(nz, dtype=int)\n",
    "\n",
    "    i = 0\n",
    "    for k, lis in dic.items():\n",
    "        for j in range(len(lis)):\n",
    "            # 将索引el附加到k以防止将具有相同ID的不同列映射到相同索引\n",
    "            ix[str(lis[j]) + str(k)] = ix.get(str(lis[j]) + str(k), 0) + 1\n",
    "            col_ix[i+j*g] = ix[str(lis[j]) + str(k)]\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    # 行索引, shape=(n*g, ), 比如n=7, g=3, 则将[0~7]*3\n",
    "    row_ix = np.repeat(np.arange(0, n), g)\n",
    "    data = np.ones(nz)\n",
    "    # 特征维数为None时\n",
    "    if p == None:\n",
    "        p = len(ix)\n",
    "    # 选择\n",
    "    ixx = np.where(col_ix < p)\n",
    "    return csr.csr_matrix((data[ixx], (row_ix[ixx], col_ix[ixx])), shape=(n,p)), ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "数据集为MovieLens100k Dataset，将其转为稀疏矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['user', 'item', 'rating', 'timestamp']\n",
    "train = pd.read_csv('data/ua.base', delimiter='\\t', names=cols)\n",
    "test = pd.read_csv('data/ua.test', delimiter='\\t', names=cols)\n",
    "\n",
    "# 矢量化数据，并转为csr矩阵\n",
    "X_train, ix = vectorize_dic({'users': train['user'].values,\n",
    "                             'items': train['item'].values}, n=len(train.index), g=2)\n",
    "X_test, ix = vectorize_dic({'users': test['user'].values,\n",
    "                            'items': test['item'].values}, ix, X_train.shape[1], n=len(test.index), g=2)\n",
    "y_train = train.rating.values\n",
    "y_test = test.rating.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义输入矩阵\n",
    "将X_train和X_test转为稀疏矩阵，用于tf模型的训练。对于大的数据集，这种方法不推荐，tf.SparseTensor可用于大的稀疏数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 2623)\n",
      "(9430, 2623)\n"
     ]
    }
   ],
   "source": [
    "# 转为稀疏矩阵\n",
    "X_train = X_train.todense()\n",
    "X_test = X_test.todense()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用tensorflow定义FM模型\n",
    "首先初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X_train.shape\n",
    "k = 10\n",
    "# 此函数可以理解为形参，用于定义过程，在执行的时候再赋具体的值\n",
    "# 确定数据的大小, 维度多少\n",
    "X = tf.placeholder('float', [None, p])\n",
    "y = tf.placeholder('float', [None, 1])\n",
    "\n",
    "# 偏差\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "# 权重, 每个变量的权重参数\n",
    "w = tf.Variable(tf.zeros([p]))\n",
    "# 两两变量组合的权重参数\n",
    "v = tf.Variable(tf.random_normal([k, p], mean=0, stddev=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义输出y值如何计算\n",
    "给定特征向量x，根据下式计算y值的输出，具体推导可看Factorization Machines Note.ipynb："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y}(\\mathbf{x}) = w_0 + \\sum_{j=1}^{p}w_jx_j + \\frac{1}{2} \\sum_{f=1}^{k} ((\\sum_{j=1}^{p}v_{j,f}x_j)^2-\\sum_{j=1}^{p}v_{j,f}^2 x_j^2)'$$\n",
    "下面对cell是对上式的实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w和x相乘, 然后使用reduce_sum, 沿着某个维度求和\n",
    "# 如a = [[1, 1, 1], [1, 1, 1]],\n",
    "# tf.reduce_sum(a, 1, keep_dims=True) = [[3], [3]], shape=(2, 1)\n",
    "# tf.reduce_sum(a, 0, keep_dims=True) = [2, 2, 2], shape=(1, 3)\n",
    "# 这里大小为(n, 1), 其中n为样本数(行数)\n",
    "linear_terms = tf.add(w0, tf.reduce_sum(tf.multiply(w, X), 1, keepdims=True))\n",
    "'''\n",
    "x = [[1, 2], \n",
    "     [1, 2]]\n",
    "y = [[0, 1], \n",
    "     [0, 1]]\n",
    "z1 = tf.multiply(x,y)\n",
    "z2 = tf.matmul(x, y)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(z1))\n",
    "    print(sess.run(z2))\n",
    "\n",
    "[[0 2]\n",
    " [0 2]]\n",
    "\n",
    "[[0 3]\n",
    " [0 3]]\n",
    "看出multiply是各元素相乘, 而matmul是矩阵相乘, 即点积法\n",
    "'''\n",
    "\n",
    "pair_interactions = 0.5 * tf.reduce_sum(\n",
    "    # (xv)^2 - (x^2 \\codt v^2)\n",
    "    tf.subtract(\n",
    "        tf.pow(\n",
    "            # 矩阵相乘, 点积法, 在平方, (xv)^2\n",
    "            tf.matmul(X, tf.transpose(v)), 2),\n",
    "        tf.matmul(tf.pow(X, 2), tf.transpose(tf.pow(v, 2)))\n",
    "    ), axis=1, keepdims=True)\n",
    "\n",
    "# 等于linear_term + pair_interactions\n",
    "y_hat = tf.add(linear_terms, pair_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "使用tensorflow实现FM的损失函数，定义为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda_w ||W||^2 + \\lambda_v ||V||^2$$\n",
    "其中 $\\lambda_w$ 和 $\\lambda_v$ 是一次项和二次项的正则系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正则项系数\n",
    "lambda_w = tf.constant(0.001, name='lambda_w')\n",
    "lambda_v = tf.constant(0.001, name='lambda_v')\n",
    "# l2正则项, lambda_w * w^2 + lambda_v * v^2\n",
    "l2_norm = tf.reduce_sum(\n",
    "    tf.add(\n",
    "        tf.multiply(lambda_w, tf.pow(w, 2)),\n",
    "        tf.multiply(lambda_v, tf.pow(v, 2))\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 平均误差\n",
    "error = tf.reduce_mean(tf.square(y - y_hat))\n",
    "# 带有正则项的损失函数, (y - y_hat)^2 + lambda_w * w^2 + lambda_v * v^2\n",
    "loss = tf.add(error, l2_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 操作\n",
    "给定损失函数，使用梯度下降更新参数：\n",
    "$$\\Theta_{i+1} = \\Theta_{i} - \\eta \\frac{\\delta L}{\\delta \\Theta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用mini-batch训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# 批量梯度下降\n",
    "def batcher(X, y=None, batch_size=-1):\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    if batch_size == -1:\n",
    "        batch_size = n_samples\n",
    "\n",
    "    # 必须大于0\n",
    "    if batch_size < 1:\n",
    "        raise ValueError('Parameter batch_size={} is unsupported'.format(batch_size))\n",
    "\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        upper_bound = min(i + batch_size, n_samples)\n",
    "        ret_x = X[i:upper_bound]\n",
    "        ret_y = None\n",
    "        if y is not None:\n",
    "            ret_y = y[i:i + batch_size]\n",
    "            yield (ret_x, ret_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估模型\n",
    "在测试集上评估训练模型的效果，使用RMSE来衡量预测的误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896872debb9b422f8e1feb76bd7b7c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.819626\n",
      "13.011467\n",
      "12.761883\n",
      "12.2216015\n",
      "11.69805\n",
      "11.463026\n",
      "10.84833\n",
      "11.002898\n",
      "10.3567915\n",
      "9.513984\n",
      "9.658576\n",
      "9.07826\n",
      "8.807209\n",
      "8.562166\n",
      "8.309016\n",
      "8.090875\n",
      "7.5858817\n",
      "7.4349427\n",
      "7.108375\n",
      "7.1056848\n",
      "6.827699\n",
      "6.4942474\n",
      "6.256871\n",
      "6.052091\n",
      "5.84168\n",
      "5.836885\n",
      "5.3031797\n",
      "5.378466\n",
      "5.123978\n",
      "5.0017066\n",
      "4.821315\n",
      "4.630307\n",
      "4.4924755\n",
      "4.4469576\n",
      "4.34924\n",
      "3.9804752\n",
      "4.027244\n",
      "3.986374\n",
      "3.915722\n",
      "3.7145824\n",
      "3.6908128\n",
      "3.4634523\n",
      "3.5396767\n",
      "3.5113034\n",
      "3.341489\n",
      "3.1985743\n",
      "3.037804\n",
      "2.947446\n",
      "2.9173622\n",
      "2.8578804\n",
      "2.8114247\n",
      "2.7320924\n",
      "2.8315914\n",
      "2.6472843\n",
      "2.6621807\n",
      "2.6291716\n",
      "2.5302184\n",
      "2.4309812\n",
      "2.3053846\n",
      "2.3376706\n",
      "2.3411977\n",
      "2.2827067\n",
      "2.1689844\n",
      "2.2699885\n",
      "2.124325\n",
      "2.110487\n",
      "2.0663626\n",
      "2.1768625\n",
      "2.0495427\n",
      "1.9921896\n",
      "1.8808839\n",
      "1.8600875\n",
      "1.9584569\n",
      "1.8720678\n",
      "1.8639582\n",
      "1.8836176\n",
      "1.7474736\n",
      "1.7285707\n",
      "1.7198129\n",
      "1.6765407\n",
      "1.7514193\n",
      "1.6685832\n",
      "1.7711302\n",
      "1.6782892\n",
      "1.5630844\n",
      "1.7193867\n",
      "1.6817102\n",
      "1.6433915\n",
      "1.5960597\n",
      "1.5973159\n",
      "1.5576217\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1000\n",
    "\n",
    "# 载入图模型\n",
    "# 初始化全局变量\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), unit='epoch'):\n",
    "        perm = np.random.permutation(X_train.shape[0])\n",
    "        # 批量梯度下降\n",
    "        for bX, bY in batcher(X_train[perm], y_train[perm], batch_size):\n",
    "            _, t = sess.run([train_op, loss], feed_dict={X: bX.reshape(-1, p), y: bY.reshape(-1, 1)})\n",
    "            print(t)\n",
    "\n",
    "    # 计算测试集的误差\n",
    "    errors = []\n",
    "    for bX, bY in batcher(X_test, y_test):\n",
    "        error.append(sess.run(error, feed_dict={X: bX.reshape(-1, p), y: bY.reshape(-1, 1)}))\n",
    "        print(errors)\n",
    "\n",
    "    # 均方根误差\n",
    "    RMSE = np.sqrt(np.array(errors).mean())\n",
    "    print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
